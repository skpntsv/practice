{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "3ba2U52hNT-3",
        "outputId": "073b1d5e-c3e8-4395-c7a7-f302ad465bc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /home/n1sko/tf_venv/lib/python3.10/site-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (2.2.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (4.13.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (2.1.3)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /home/n1sko/tf_venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /home/n1sko/tf_venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /home/n1sko/tf_venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: tf2onnx in /home/n1sko/tf_venv/lib/python3.10/site-packages (1.16.1)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tf2onnx) (2.1.3)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tf2onnx) (1.17.0)\n",
            "Requirement already satisfied: requests in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tf2onnx) (2.32.3)\n",
            "Requirement already satisfied: six in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tf2onnx) (1.17.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tf2onnx) (25.2.10)\n",
            "Requirement already satisfied: protobuf~=3.20 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from requests->tf2onnx) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from requests->tf2onnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from requests->tf2onnx) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/n1sko/tf_venv/lib/python3.10/site-packages (from requests->tf2onnx) (2025.1.31)\n",
            "Requirement already satisfied: numpy in /home/n1sko/tf_venv/lib/python3.10/site-packages (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install tf2onnx\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BMk-B46XOrIS",
        "outputId": "a06ae7e8-5a1e-45e6-e01d-ab925f864968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (3.20.3)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.20.1\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LRTaOx7bUOPL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-03 11:50:59.408678: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-03 11:50:59.705964: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743655859.811631   47831 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743655859.843008   47831 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1743655860.083020   47831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1743655860.083057   47831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1743655860.083061   47831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1743655860.083062   47831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-04-03 11:51:00.110910: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Для экспорта в ONNX и проверки модели\n",
        "import tf2onnx\n",
        "import onnx\n",
        "import onnxruntime as ort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "lGgtgrXNSUD4",
        "outputId": "a739aaf0-6e57-4abe-9508-49a98a061a12"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mnist_model\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"mnist_model\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,212,288</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m832\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m51,264\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m3,212,288\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m10,250\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,274,634</span> (12.49 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,274,634\u001b[0m (12.49 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,274,634</span> (12.49 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,274,634\u001b[0m (12.49 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 114ms/step - accuracy: 0.9051 - loss: 0.2928 - val_accuracy: 0.9890 - val_loss: 0.0389\n",
            "Model saved in file: model_10class/model_10class.weights.h5\n"
          ]
        }
      ],
      "source": [
        "# Парсинг аргументов командной строки\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('data_dir', type=str, help=\"Путь для хранения/загрузки данных (будет использован для сохранения модели)\")\n",
        "# parser.add_argument('class_num', type=int, help=\"Количество классов (2, 10 или 20)\")\n",
        "# parser.add_argument('train_round', type=int, help=\"Количество эпох для обучения\")\n",
        "# args = parser.parse_args()\n",
        "\n",
        "# DATA_DIR = args.data_dir\n",
        "DATA_DIR = \"FlowAllLayers/\"\n",
        "# CLASS_NUM = args.class_num\n",
        "CLASS_NUM = 10\n",
        "# TRAIN_ROUND = args.train_round\n",
        "TRAIN_ROUND = 1\n",
        "\n",
        "# Словари для наименования классов (пример – можно расширить по необходимости)\n",
        "dict_2class = {0: 'Benign', 1: 'Malware'}\n",
        "dict_10class_benign = {0: 'BitTorrent', 1: 'Facetime', 2: 'FTP', 3: 'Gmail', 4: 'MySQL', 5: 'Outlook', 6: 'Skype', 7: 'SMB', 8: 'Weibo', 9: 'WorldOfWarcraft'}\n",
        "dict_10class_malware = {0: 'Cridex', 1: 'Geodo', 2: 'Htbot', 3: 'Miuref', 4: 'Neris', 5: 'Nsis-ay', 6: 'Shifu', 7: 'Tinba', 8: 'Virut', 9: 'Zeus'}\n",
        "dict_20class = {**dict_10class_benign, **dict_10class_malware}  # объединение двух словарей\n",
        "\n",
        "# Загрузка MNIST через tf.keras (данные автоматически загружаются и кэшируются)\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Приведение данных к формату float и нормализация [0, 1]\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test  = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Добавляем размерность канала (MNIST – чёрно-белые изображения)\n",
        "x_train = np.expand_dims(x_train, -1)  # форма (num_samples, 28, 28, 1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Если модель предназначена для классов, отличных от стандартных 10,\n",
        "# можно добавить маппинг или использовать только подмножество данных.\n",
        "# Здесь предполагается, что для CLASS_NUM==10 используется весь MNIST.\n",
        "if CLASS_NUM not in [2, 10, 20]:\n",
        "    print(\"Не поддерживаемое количество классов. Используйте 2, 10 или 20.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Преобразование меток в one-hot представление (учтите, что для 2 и 20 классов нужна соответствующая предобработка)\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test  = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Если требуется изменить число классов (например, для двоичной классификации),\n",
        "# можно взять только часть классов или объединить их. Здесь оставляем стандартное число классов MNIST.\n",
        "# В дальнейшем при выводе результатов можно использовать соответствующий словарь:\n",
        "if CLASS_NUM == 2:\n",
        "    class_dict = dict_2class\n",
        "elif CLASS_NUM == 10:\n",
        "    # Для демонстрации можно выбрать benign или malware по имени каталога DATA_DIR\n",
        "    folder = os.path.basename(DATA_DIR)\n",
        "    if folder.startswith('Benign'):\n",
        "        class_dict = dict_10class_benign\n",
        "    else:\n",
        "        class_dict = dict_10class_malware\n",
        "elif CLASS_NUM == 20:\n",
        "    class_dict = dict_20class\n",
        "\n",
        "# Определяем модель с использованием Keras API\n",
        "inputs = keras.Input(shape=(28, 28, 1), name=\"input\")\n",
        "x = layers.Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same')(inputs)\n",
        "x = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10, activation='softmax', name=\"output\")(x)  # обучаем на MNIST (10 классов)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Формирование имени модели и пути сохранения\n",
        "model_dir = f\"model_{CLASS_NUM}class\"\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "checkpoint_path = os.path.join(model_dir, f\"{model_dir}.weights.h5\")\n",
        "\n",
        "# Если сохранённая модель существует – загружаем веса, иначе обучаем\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "    print(\"Model restored:\", checkpoint_path)\n",
        "else:\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=50,\n",
        "              epochs=TRAIN_ROUND,\n",
        "              validation_split=0.1)\n",
        "    model.save_weights(checkpoint_path)\n",
        "    print(\"Model saved in file:\", checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ2sWq4sIRVm",
        "outputId": "62e731b4-e6f2-460e-a3d5-e677e94619eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9873\n"
          ]
        }
      ],
      "source": [
        "# Оценка точности на тестовом наборе\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test accuracy: {:.4f}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs4Bu-1yWEwV",
        "outputId": "a42306ab-07a5-412b-9242-41fbc02ce1af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX model exported to: model_10class/model_10class.onnx\n"
          ]
        }
      ],
      "source": [
        "# Экспорт модели в формат ONNX\n",
        "# Для экспорта задаём сигнатуру входного тензора\n",
        "spec = (tf.TensorSpec((None, 28, 28, 1), tf.float32, name=\"input\"),)\n",
        "output_path = os.path.join(model_dir, f\"{model_dir}.onnx\")\n",
        "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13, output_path=output_path)\n",
        "print(\"ONNX model exported to:\", output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abuitmBNWGOE",
        "outputId": "5fb42a20-115b-4685-808f-12fac247d372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX model check passed.\n"
          ]
        }
      ],
      "source": [
        "# Проверка корректности экспортированной ONNX модели\n",
        "onnx_model = onnx.load(output_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print(\"ONNX model check passed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWgkvrLbWKg9",
        "outputId": "358dc684-ffec-4c90-a3a1-90af1ad9c2c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX model prediction (first sample): [[1.6238681e-11 1.1650045e-10 1.2089139e-07 8.3929422e-07 2.0441404e-13\n",
            "  3.7070047e-10 7.7068495e-15 9.9999905e-01 2.2729889e-11 2.6208479e-08]]\n"
          ]
        }
      ],
      "source": [
        "# Пробный запуск инференса через onnxruntime для проверки работы модели\n",
        "ort_session = ort.InferenceSession(output_path)\n",
        "def run_onnx_inference(input_data):\n",
        "    # onnxruntime требует numpy-массив\n",
        "    ort_inputs = {ort_session.get_inputs()[0].name: input_data}\n",
        "    ort_outs = ort_session.run(None, ort_inputs)\n",
        "    return ort_outs[0]\n",
        "\n",
        "# Пример: получение предсказания для одного изображения из тестового набора\n",
        "sample = x_test[:1]\n",
        "onnx_pred = run_onnx_inference(sample)\n",
        "print(\"ONNX model prediction (first sample):\", onnx_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RYQlEkwVC_b",
        "outputId": "5c080162-b536-4cd7-8946-c4c49dfc0b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Тестовое изображение сохранено как test_image.bmp\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Загрузка MNIST\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Нормализация\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Выбор первого тестового изображения\n",
        "sample = x_test[0]  # Размер: 28×28\n",
        "\n",
        "# Сохранение как BMP\n",
        "plt.imsave(\"test_image.bmp\", sample, cmap=\"gray\")\n",
        "print(\"Тестовое изображение сохранено как test_image.bmp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGErLDSheOSJ",
        "outputId": "23cbbf4c-8cd6-4a9d-9340-f7e2df47491b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Входной тензор сохранён в файле 'prepared_input'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "(_, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Приведение к формату float и нормализация\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Добавляем размерность канала: (num_samples, 28, 28, 1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Выбираем один образец (например, первый)\n",
        "sample = x_test[0]  # shape: (28, 28, 1)\n",
        "\n",
        "# Если требуется пакетный ввод, можно добавить размерность batch:\n",
        "sample = np.expand_dims(sample, 0)  # теперь shape: (1, 28, 28, 1)\n",
        "\n",
        "# Для записи в бинарный файл нам нужен одномерный массив из float32\n",
        "# (Ожидается, что C++ код считает 1*28*28*1 элементов)\n",
        "sample_flat = sample.reshape(-1)\n",
        "\n",
        "# Сохраняем в файл (будет создан файл 'prepared_input' размером 28*28*1*4 байт)\n",
        "sample_flat.tofile(\"prepared_input\")\n",
        "print(\"Входной тензор сохранён в файле 'prepared_input'\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfR9zkVuxhyanEQanXagN8",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
